import streamlit as st
import pandas as pd
import os
import xml.etree.ElementTree as ET
from datetime import date
import re
import time
import pickle
import numpy as np
import io
import unicodedata
#format_date_to_brazilian
#df['M√™s']
# Page configuration
st.set_page_config(
    page_title="XML Invoice Processor",
    page_icon=":page_with_curl:",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Main title
st.header("üìÉ Processamento de Arquivos XML")

def slugify(text):
    """
    Convert a text string into a slug format.
    - Convert to lowercase
    - Remove special characters
    - Replace spaces with hyphens
    - Remove consecutive hyphens
    """
    if not isinstance(text, str):
        text = str(text)
    
    # Convert to lowercase and normalize unicode characters
    text = text.lower()
    text = unicodedata.normalize('NFKD', text)
    text = text.encode('ascii', 'ignore').decode('utf-8')
    
    # Replace any non-alphanumeric character with a hyphen
    text = re.sub(r'[^a-z0-9]+', '-', text)
    
    # Remove leading and trailing hyphens
    text = text.strip('-')
    
    # Replace multiple consecutive hyphens with a single hyphen
    text = re.sub(r'-+', '-', text)
    
    return text

def clean_description(description):
    """Remove m√∫ltiplos espa√ßos consecutivos e espa√ßos no in√≠cio e no final da string."""
    if description is None:
        return ""
    description = re.sub(' +', ' ', description)
    description = description.strip()
    return description

def filter_info_adic(info_adic):
    """Filtra a informa√ß√£o adicional para encontrar prefixos espec√≠ficos e formata o texto resultante."""
    if not info_adic:
        return ""
    prefixos = ['4501', '4502', '4503', '4504', '4505']
    palavras = info_adic.split()
    palavras_filtradas = [p[:10] for p in palavras if any(p.startswith(prefix) for prefix in prefixos)]
    if palavras_filtradas:
        return ' '.join(palavras_filtradas)
    return ""

def format_value(value_str):
    """Formata o valor substituindo v√≠rgulas por pontos e convertendo para float se poss√≠vel."""
    if isinstance(value_str, str):
        value_str = value_str.replace('.', '').replace(',', '.')
        try:
            return float(value_str)
        except ValueError:
            return value_str
    elif isinstance(value_str, (int, float)):
        return value_str
    return ""

class ReadXML:
    def __init__(self, files):
        self.files = files

    def nfe_data(self, xml_file):
        """Extrai dados da NFe de um arquivo XML e retorna uma lista de dados para cada item da nota fiscal."""
        root = ET.parse(xml_file).getroot()
        nsNFe = {"ns": "http://www.portalfiscal.inf.br/nfe"}
        
# Acessar o elemento <infNFe> e extrair o atributo Id
        infNFe = root.find(".//ns:infNFe", nsNFe)
        if infNFe is not None:
            chNFe = infNFe.attrib.get('Id', '')
        else:
            chNFe = ""

        
        #Dados gerais
        NFe = self.check_none(root.find("./ns:NFe/ns:infNFe/ns:ide/ns:nNF", nsNFe))
        serie = self.check_none(root.find("./ns:NFe/ns:infNFe/ns:ide/ns:serie", nsNFe))
        natOp = self.check_none(root.find("./ns:NFe/ns:infNFe/ns:ide/ns:natOp", nsNFe))
        data_emissao = self.check_none(root.find("./ns:NFe/ns:infNFe/ns:ide/ns:dhEmi", nsNFe))
        #data_emissao = f"{data_emissao[8:10]}/{data_emissao[5:7]}/{data_emissao[:4]}" if data_emissao else ""
        info_adic = self.check_none(root.find("./ns:NFe/ns:infNFe/ns:infAdic/ns:infCpl", nsNFe))
        dVenc = self.check_none(root.find("./ns:NFe/ns:infNFe/ns:cobr/ns:dup/ns:dVenc", nsNFe))
        #dVenc = f"{dVenc[8:10]}/{dVenc[5:7]}/{dVenc[:4]}" if dVenc else ""
        #dVenc = dVenc.replace("//", "")

        # Dados Emitente
        emit = root.find("./ns:NFe/ns:infNFe/ns:emit", nsNFe)
        emit_data = {
            'CNPJ Emitente': self.check_none(emit.find("ns:CNPJ", nsNFe)) if emit is not None else "",
            'Nome Emitente': self.check_none(emit.find("ns:xNome", nsNFe)) if emit is not None else "",
            'IE Emitente': self.check_none(emit.find("ns:IE", nsNFe)) if emit is not None else "",
            'Endereco Emitente': {
                'Logradouro': self.check_none(emit.find("ns:enderEmit/ns:xLgr", nsNFe)) if emit is not None else "",
                'N√∫mero': self.check_none(emit.find("ns:enderEmit/ns:nro", nsNFe)) if emit is not None else "",
                'Complemento': self.check_none(emit.find("ns:enderEmit/ns:complemento", nsNFe)) if emit is not None else "",
                'Bairro': self.check_none(emit.find("ns:enderEmit/ns:xBairro", nsNFe)) if emit is not None else "",
                'Munic√≠pio': self.check_none(emit.find("ns:enderEmit/ns:xMun", nsNFe)) if emit is not None else "",
                'UF': self.check_none(emit.find("ns:enderEmit/ns:UF", nsNFe)) if emit is not None else "",
                'CEP': self.check_none(emit.find("ns:enderEmit/ns:CEP", nsNFe)) if emit is not None else "",
                'Pa√≠s': self.check_none(emit.find("ns:enderEmit/ns:cPais", nsNFe)) if emit is not None else ""
            }
        }

        # Dados Destinat√°rio
        dest = root.find("./ns:NFe/ns:infNFe/ns:dest", nsNFe)
        dest_data = {
            'CNPJ Destinat√°rio': self.check_none(dest.find("ns:CNPJ", nsNFe)) if dest is not None else "",
            'Nome Destinat√°rio': self.check_none(dest.find("ns:xNome", nsNFe)) if dest is not None else "",
            'IE Destinat√°rio': self.check_none(dest.find("ns:IE", nsNFe)) if dest is not None else "",
            'Endereco Destinat√°rio': {
                'Logradouro': self.check_none(dest.find("ns:enderDest/ns:xLgr", nsNFe)) if dest is not None else "",
                'N√∫mero': self.check_none(dest.find("ns:enderDest/ns:nro", nsNFe)) if dest is not None else "",
                'Complemento': self.check_none(dest.find("ns:enderDest/ns:complemento", nsNFe)) if dest is not None else "",
                'Bairro': self.check_none(dest.find("ns:enderDest/ns:xBairro", nsNFe)) if dest is not None else "",
                'Munic√≠pio': self.check_none(dest.find("ns:enderDest/ns:xMun", nsNFe)) if dest is not None else "",
                'UF': self.check_none(dest.find("ns:enderDest/ns:UF", nsNFe)) if dest is not None else "",
                'CEP': self.check_none(dest.find("ns:enderDest/ns:CEP", nsNFe)) if dest is not None else "",
                'Pa√≠s': self.check_none(dest.find("ns:enderDest/ns:cPais", nsNFe)) if dest is not None else ""
            }
        }

        # Dados Cobran√ßa
        cobr = root.find("./ns:NFe/ns:infNFe/ns:cobr", nsNFe)
        cobr_data = self.extract_cobr_data(cobr, nsNFe) if cobr is not None else {}

        # Dados do Item
        itemNota = 1
        notas = []

        for item in root.findall("./ns:NFe/ns:infNFe/ns:det", nsNFe):
            # Dados do Item
            cod = self.check_none(item.find(".ns:prod/ns:cProd", nsNFe))
            qntd = self.check_none(item.find(".ns:prod/ns:qCom", nsNFe))
            descricao = self.check_none(item.find(".ns:prod/ns:xProd", nsNFe))
            unidade_medida = self.check_none(item.find(".ns:prod/ns:uCom", nsNFe))
            vlUnProd = self.check_none(item.find(".ns:prod/ns:vUnCom", nsNFe))
            valorProd = self.check_none(item.find(".ns:prod/ns:vProd", nsNFe))
            ncm = self.check_none(item.find(".ns:prod/ns:NCM", nsNFe))
            cfop = self.check_none(item.find(".ns:prod/ns:CFOP", nsNFe))
            xPed = self.check_none(item.find(".ns:prod/ns:xPed", nsNFe))
            nItemPed = self.check_none(item.find(".ns:prod/ns:nItemPed", nsNFe))
            infAdProd = self.check_none(item.find(".ns:infAdProd", nsNFe))

            valorNfe = format_value(self.check_none(root.find("./ns:NFe/ns:infNFe/ns:total/ns:ICMSTot/ns:vNF", nsNFe)))
            valor_frete = format_value(self.check_none(root.find("./ns:NFe/ns:infNFe/ns:total/ns:ICMSTot/ns:vFrete", nsNFe)))
            data_importacao = self.check_none(root.find("./ns:NFe/ns:infNFe/ns:transp/ns:vol/ns:veicId", nsNFe))
            usuario = self.check_none(root.find("./ns:NFe/ns:infNFe/ns:transp/ns:vol/ns:placa", nsNFe))
            data_saida = self.check_none(root.find("./ns:NFe/ns:infNFe/ns:transp/ns:vol/ns:uf", nsNFe))

            dados = [chNFe, NFe, serie, natOp, data_emissao, info_adic, dVenc, 
                    emit_data['CNPJ Emitente'], emit_data['Nome Emitente'],
                    dest_data['CNPJ Destinat√°rio'], dest_data['Nome Destinat√°rio'], valorNfe, valor_frete, itemNota, cod, qntd, descricao, unidade_medida, vlUnProd, valorProd, ncm, cfop , xPed, nItemPed,
                    infAdProd, data_importacao, usuario, data_saida,
                    cobr_data.get('Fatura', ''), cobr_data.get('Duplicata', ''), cobr_data.get('Valor Original', ''), cobr_data.get('Valor Pago', ''),
                    emit_data['Endereco Emitente']['Logradouro'], emit_data['Endereco Emitente']['N√∫mero'], emit_data['Endereco Emitente']['Complemento'],
                    emit_data['Endereco Emitente']['Bairro'], emit_data['Endereco Emitente']['Munic√≠pio'], emit_data['Endereco Emitente']['UF'],
                    emit_data['Endereco Emitente']['CEP'], emit_data['Endereco Emitente']['Pa√≠s'],
                    dest_data['Endereco Destinat√°rio']['Logradouro'], dest_data['Endereco Destinat√°rio']['N√∫mero'],
                    dest_data['Endereco Destinat√°rio']['Complemento'], dest_data['Endereco Destinat√°rio']['Bairro'],
                    dest_data['Endereco Destinat√°rio']['Munic√≠pio'], dest_data['Endereco Destinat√°rio']['UF'],
                    dest_data['Endereco Destinat√°rio']['CEP'], dest_data['Endereco Destinat√°rio']['Pa√≠s']]
            
            notas.append(dados)
            itemNota += 1
        
        return notas

    def check_none(self, var):
        """Verifica se o elemento XML √© None e retorna uma string vazia, caso contr√°rio, retorna o texto do elemento."""
        if var is None:
            return ""
        try:
            return var.text.replace('.', '.') if var.text else ""
        except:
            return ""

    def extract_cobr_data(self, cobr, nsNFe):
        """Extrai os dados da se√ß√£o <cobr>, incluindo <fat> e <dup>."""
        if cobr is None:
            return {
                'Fatura': '',
                'Duplicata': '',
                'Valor Original': '',
                'Valor Pago': ''
            }
        
        cobr_data = {
            'Fatura': self.check_none(cobr.find("ns:fat/ns:nFat", nsNFe)),
            'Duplicata': self.check_none(cobr.find("ns:dup/ns:nDup", nsNFe)),
            'Valor Original': format_value(self.check_none(cobr.find("ns:fat/ns:vOrig", nsNFe))),
            'Valor Pago': format_value(self.check_none(cobr.find("ns:fat/ns:vLiq", nsNFe)))
        }
        return cobr_data

    def process_xml_files(self):
        """Processa todos os arquivos XML carregados"""
        dados = []
        for uploaded_file in self.files:
            result = self.nfe_data(uploaded_file)
            dados.extend(result)
        return dados

def main():
    # # Page configuration
    # st.set_page_config(
    #     page_title="XML Invoice Processor", 
    #     page_icon=":page_with_curl:", 
    #     layout="wide"
    # )

    # # Main title
    # st.title("XML Invoice Processor üìÑ")

    # Create tabs
    tab1, tab2, tab3 = st.tabs(["üì§ Upload e Extra√ß√£o", "üìä Visualiza√ß√£o de Dados", "‚ùì Como Utilizar"])

    with tab1:
        # File uploader for XML files
        uploaded_files = st.file_uploader(
            "Upload XML Files", 
            type=['xml'], 
            accept_multiple_files=True
        )

        if uploaded_files:
            # Progress bar
            progress_bar = st.progress(0)
            for percent_complete in range(100):
                time.sleep(0.01)
                progress_bar.progress(percent_complete + 1)
            progress_bar.empty()

            # Process XML files
            xml_reader = ReadXML(uploaded_files)
            dados = xml_reader.process_xml_files()

    # Criando DataFrame Pandas
            df = pd.DataFrame(dados, columns=[
                'chaveNfe', 'NFe', 'S√©rie', 'natOp','Data de Emiss√£o', 'info_adic', 'dVenc', 'CNPJ Emitente', 'Nome Emitente',
                'CNPJ Destinat√°rio', 'Nome Destinat√°rio', 'Valor NF-e', 'Valor Frete', 'Item Nota', 'C√≥d Produto',
                'Quantidade', 'Descri√ß√£o', 'Unidade Medida', 'vlUnProd', 'vlTotProd', 'ncm', 'cfop' ,'xPed', 'nItemPed',
                'infAdProd', 'Data Importa√ß√£o', 'Usu√°rio', 'Data Sa√≠da', 'Fatura', 'Duplicata', 'Valor Original', 'Valor Pago',
                'Logradouro Emitente', 'N√∫mero Emitente', 'Complemento Emitente', 'Bairro Emitente', 'Munic√≠pio Emitente',
                'UF Emitente', 'CEP Emitente', 'Pa√≠s Emitente', 'Logradouro Destinat√°rio', 'N√∫mero Destinat√°rio',
                'Complemento Destinat√°rio', 'Bairro Destinat√°rio', 'Munic√≠pio Destinat√°rio', 'UF Destinat√°rio',
                'CEP Destinat√°rio', 'Pa√≠s Destinat√°rio'
            ])

            colunas = [
                'chaveNfe', 'NFe', 'Nome Emitente', 'Descri√ß√£o', 'S√©rie', 'natOp','Data de Emiss√£o', 'info_adic', 'dVenc', 
                'CNPJ Emitente', 'CNPJ Destinat√°rio', 'Nome Destinat√°rio', 'Valor NF-e', 'Valor Frete', 'Item Nota', 
                'C√≥d Produto', 'Quantidade', 'Unidade Medida', 'vlUnProd', 'vlTotProd', 'ncm', 'cfop', 'xPed', 'nItemPed', 
                'infAdProd', 'Data Importa√ß√£o', 'Usu√°rio', 'Data Sa√≠da', 'Fatura', 'Duplicata', 'Valor Original', 
                'Valor Pago', 'Logradouro Emitente', 'N√∫mero Emitente', 'Complemento Emitente', 'Bairro Emitente', 
                'Munic√≠pio Emitente', 'UF Emitente', 'CEP Emitente', 'Pa√≠s Emitente', 'Logradouro Destinat√°rio', 
                'N√∫mero Destinat√°rio', 'Complemento Destinat√°rio', 'Bairro Destinat√°rio', 'Munic√≠pio Destinat√°rio', 
                'UF Destinat√°rio', 'CEP Destinat√°rio', 'Pa√≠s Destinat√°rio'
            ]

            df = df.reindex(columns=colunas)

            # Create unique identifier using slugify
            df['unique'] = df['NFe'].astype(str) + '-' + df['Item Nota'].astype(str) + '-' + df['Descri√ß√£o'].astype(str)
            df['unique'] = df['unique'].apply(slugify)
            
            # Remove duplicates based on the slugified unique column
            df.drop_duplicates(subset='unique', inplace=True)
            
            # df=df_formatted
            def convert_to_decimal(df, columns, decimal_places=2):
                """Converte v√°rias colunas para float (decimais) e arredonda para o n√∫mero especificado de casas decimais."""
                for column in columns:
                    # Converte para float e for√ßa valores inv√°lidos para NaN
                    df[column] = pd.to_numeric(df[column], errors='coerce').astype(float)
                    # Arredonda para o n√∫mero de casas decimais especificado
                    df[column] = df[column].round(decimal_places)
                return df

            # Supondo que voc√™ queira converter as colunas 'preco' e 'quantidade' para decimais com duas casas
            columns_to_convert = ['Quantidade','vlUnProd','vlTotProd']

            # Converter as colunas para decimal (float) com duas casas decimais
            df = convert_to_decimal(df, columns_to_convert, decimal_places=2) 
            
            # Fun√ß√£o para formatar os n√∫meros corretamente, lidando com valores vazios
            def formatar_numero(x):
                if pd.isna(x) or x == '':  # Se o valor for nulo ou string vazia
                    return None  # Retorna None para manter o valor como NaN
                else:
                    x_str = str(int(x))  # Certificar que seja inteiro e sem pontos ou espa√ßos
                    
                    # Garantindo que o n√∫mero tenha pelo menos dois d√≠gitos
                    if len(x_str) > 2:
                        # Inserindo o ponto decimal entre os dois √∫ltimos d√≠gitos
                        return x_str[:-2] + "." + x_str[-2:]
                    else:
                        # Se o n√∫mero for menor que 100, apenas adiciona '0.xx'
                        return "0." + x_str.zfill(2)


            # Aplicar a fun√ß√£o diretamente nas colunas existentes
            colunas_para_formatar = ['Valor NF-e', 'Valor Original', 'Valor Pago']
            
            for coluna in colunas_para_formatar:
                # Formatar os n√∫meros na coluna e converter para float
                df[coluna] = df[coluna].apply(formatar_numero).astype(float)
                    
            # Agrupando por 'Category' e somando os valores de 'Value'
            df['vlNf'] = df.groupby('chaveNfe')['vlTotProd'].transform('sum')

            df['Descri√ß√£o'] = df['Descri√ß√£o'].apply(clean_description).str.upper()
            
            # Aplicar a fun√ß√£o para filtrar e formatar a coluna 'info_adic'
            df['po'] = df['info_adic'].fillna("") + " " + df['xPed'].fillna("") + " " + df['nItemPed'].fillna("") + " " + df['infAdProd'].fillna("")
            df['po'] = df['po'].apply(filter_info_adic)
            
            # Fun√ß√£o para truncar os primeiros 10 caracteres
            def truncate_to_10_chars(text):
                return text[:10] if text else ""

            df['po'] = df['po'].apply(truncate_to_10_chars)


            # Fun√ß√£o para obter o primeiro valor n√£o vazio para cada 'chaveNfe'
            def get_first_non_empty_po(df):
                first_non_empty_po = {}
                for chave, po in zip(df['chaveNfe'], df['po']):
                    if pd.notna(po) and po != '' and chave not in first_non_empty_po:
                        first_non_empty_po[chave] = po
                return first_non_empty_po
                

            # Atualiza a coluna 'po' com o primeiro valor n√£o vazio
            first_po_dict = get_first_non_empty_po(df)
            df['po'] = df['chaveNfe'].map(first_po_dict)                   
              
            def format_date_to_brazilian(df, columns):
                """
                Converte as colunas especificadas para o formato de data brasileiro (dd/mm/aaaa).
                
                :param df: DataFrame a ser modificado
                :param columns: Lista de nomes das colunas a serem formatadas
                :return: DataFrame com as colunas formatadas como datas brasileiras
                """
                for column in columns:
                    # First, try converting to datetime, handling different potential input formats
                    try:
                        # Try multiple datetime parsing strategies
                        df[column] = pd.to_datetime(
                            df[column], 
                            format='%Y-%m-%d',  # ISO format
                            errors='coerce'
                        )
                    except:
                        try:
                            df[column] = pd.to_datetime(
                                df[column], 
                                format='%d/%m/%Y',  # Brazilian format
                                errors='coerce'
                            )
                        except:
                            # If conversion fails, leave the column as is
                            continue
                    
                    # Format to Brazilian date string only for non-null values
                    df[column] = df[column].dt.strftime('%d/%m/%Y')
                
                return df

            # Aplicar a formata√ß√£o desejada
            df = format_date_to_brazilian(df, ['dVenc'])
                                        
            #Fun√ß√£o para formatar colunas como moeda brasileira (BRL)
            
            def format_to_brl_currency(df, columns):
                """
                Formata as colunas especificadas do DataFrame para o formato de moeda brasileiro (Real) com duas casas decimais.
                Valores n√£o num√©ricos ou vazios s√£o substitu√≠dos por uma string vazia.
                
                :param df: DataFrame a ser modificado
                :param columns: Lista de nomes das colunas a serem formatadas
                :return: DataFrame com as colunas formatadas como moeda brasileira
                """
                for column in columns:
                    df[column] = pd.to_numeric(df[column], errors='coerce')

                    #df[column] = df[column].apply(lambda x: f'R${x:,.2f}'.replace('.', ',') if pd.notna(x) else '')
                    
                    # Convertendo valores para formato desejado
                    df[column] = df[column].apply(lambda x: 'R$ {:,.2f}'.format(x / 1))
                    df[column] = df[column].str.replace(',', 'X').str.replace('.', ',').str.replace('X', '.')
                return df

            df = df
                            
            def convert_columns_to_numeric(df, columns):
                """Converte v√°rias colunas para num√©rico, for√ßando erros para NaN."""
                for column in columns:
                    df[column] = pd.to_numeric(df[column], errors='coerce')
                return df

            # Supondo que voc√™ queira converter as colunas 'po' e 'NFe'
            columns_to_convert = ['po','NFe','S√©rie','CNPJ Emitente','CNPJ Destinat√°rio','ncm','cfop','CEP Emitente','Pa√≠s Emitente','CEP Destinat√°rio','Pa√≠s Destinat√°rio'] 
            
            # Converter as colunas relevantes para num√©rico
            df = convert_columns_to_numeric(df, columns_to_convert)   

            # Ordenar o DataFrame pela coluna 'Data' do mais novo para o mais velho
            df = df.sort_values(by='Data de Emiss√£o', ascending=False)  

            # Selecionando colunas, renomeando e reordenando
            colunas_para_exibir =['chaveNfe','NFe','Nome Emitente','Descri√ß√£o','S√©rie','natOp','Data de Emiss√£o',
                                    'info_adic','dVenc','CNPJ Destinat√°rio','Nome Destinat√°rio','Valor NF-e',
                                    'Valor Frete','Item Nota','C√≥d Produto','Quantidade','Unidade Medida','vlUnProd','vlTotProd',
                                    'ncm','cfop','xPed','nItemPed','infAdProd','Data Importa√ß√£o','Usu√°rio','Data Sa√≠da','Fatura',
                                    'Duplicata','Valor Original','Valor Pago',
                                    'Logradouro Emitente','N√∫mero Emitente','Complemento Emitente','Bairro Emitente','Munic√≠pio Emitente','UF Emitente','CEP Emitente','Pa√≠s Emitente',
                                    'Logradouro Destinat√°rio','N√∫mero Destinat√°rio','Complemento Destinat√°rio','Bairro Destinat√°rio','Munic√≠pio Destinat√°rio','UF Destinat√°rio','CEP Destinat√°rio','Pa√≠s Destinat√°rio',
                                    'vlNf','po','unique']
            
            # Renomear as colunas

            df = df.rename(columns={'NFe': 'nNf', 'Data de Emiss√£o': 'dtEmi','Item Nota':'itemNf','Descri√ß√£o':'nomeMaterial','ncm':'ncm','Quantidade':'qtd',
                            'Unidade Medida':'und','vlUnProd':'vlUnProd','vlTotProd':'vlTotProd','Valor NF-e':'vlTotalNf',
                            'dVenc':'dVenc','po':'po',
                            'chaveNfe':'chNfe',
                            'Nome Emitente': 'emitNome','CNPJ Emitente':'emitCnpj','Logradouro Emitente':'emitLogr','N√∫mero Emitente':'emitNr','Complemento Emitente':'emitCompl','Bairro Emitente':'emitBairro','Munic√≠pio Emitente':'emitMunic','UF Emitente':'emitUf','CEP Emitente':'emitCep','Pa√≠s Emitente':'emitPais',
                            'Nome Destinat√°rio': 'destNome','CNPJ Destinat√°rio':'destCnpj','Logradouro Destinat√°rio':'destLogr','N√∫mero Destinat√°rio':'destNr','Complemento Destinat√°rio':'destCompl','Bairro Destinat√°rio':'destBairro','Munic√≠pio Destinat√°rio':'destMunic','UF Destinat√°rio':'destUf','CEP Destinat√°rio':'destCep','Pa√≠s Destinat√°rio':'destPais',
                            'cfop':'cfop','unique':'unique'})

            # Exibir apenas as colunas renomeadas
            colunas_renomeadas = ['nNf', 'dtEmi', 'itemNf','nomeMaterial','ncm','qtd','und','vlUnProd','vlTotProd','vlTotalNf','po','dVenc','chNfe',
                                    'emitNome','emitCnpj','emitLogr','emitNr','emitCompl','emitBairro','emitMunic','emitUf','emitCep','emitPais',
                                    'destNome','destCnpj','destLogr','destNr','destCompl','destBairro','destMunic','destUf','destCep','destPais',
                                    'cfop','unique']
            
            df= df[colunas_renomeadas]
            
            
            # Converter as colunas para string
            df['emitCnpj'] = df['emitCnpj'].astype(str).replace('.0','')
            df['destCnpj'] = df['destCnpj'].astype(str).replace('.0','')

            # Garantir que as colunas tenham 14 d√≠gitos
            df['emitCnpj'] = df['emitCnpj'].str.zfill(14)
            df['destCnpj'] = df['destCnpj'].str.zfill(14)
            
            st.write(f"Quantidade de linhas: {df.shape[0]}")
                       
            # Create a new column counting invoices per PO
            po_invoice_counts = df.groupby('po')['chNfe'].nunique().reset_index()
            po_invoice_counts.columns = ['po', 'total_invoices_per_po']
            df = df.merge(po_invoice_counts, on='po', how='left')
            
            def categorize_transaction(row):
                """
                Categorize transactions based on CFOP and whether Andritz is the emitter
                Includes categories for maintenance, repairs, and returns
                """
                cfop = str(row['cfop'])
                emit_nome = str(row['emitNome']).upper()
                
                # Check if Andritz is the emitter
                is_andritz_emitter = 'ANDRITZ' in emit_nome
                
                # Manuten√ß√£o, Conserto e Reparo CFOPs
                manutencao_entrada_cfops = ['1915', '2915', '1916', '2916']  # Entrada para reparo
                manutencao_saida_cfops = ['5915', '6915', '5916', '6916']    # Sa√≠da para reparo
                
                # Retorno de mercadoria CFOPs
                retorno_entrada_cfops = ['1201', '1202', '1203', '1204', '1410', '1411', '1503', '1504', 
                                        '2201', '2202', '2203', '2204', '2410', '2411', '2503', '2504']
                retorno_saida_cfops = ['5201', '5202', '5210', '5410', '5411', '5412', '5413', '5503', '5504',
                                    '6201', '6202', '6210', '6410', '6411', '6412', '6413', '6503', '6504']
                
                # Remessa CFOPs
                remessa_entrada_cfops = ['1554','1901', '1902', '1903', '1904', '1905', '1906', '1907', '1908', '1909', '1913', '1914', '1921',
                                        '2901', '2902', '2903', '2904', '2905', '2906', '2907', '2908', '2909', '2913', '2914', '2921']
                remessa_saida_cfops = ['5901', '5902', '5903', '5904', '5905', '5906', '5907', '5908', '5909', '5913', '5914', '5921',
                                    '6901', '6902', '6903', '6904', '6905', '6906', '6907', '6908', '6909', '6913', '6914', '6921']
                
                # Devolu√ß√£o CFOPs
                devolucao_entrada_cfops = ['1201', '1202', '1203', '1204', '1209', '1410', '1411', '1503', '1504', '1921',
                                        '2201', '2202', '2203', '2204', '2209', '2410', '2411', '2503', '2504', '2921']
                devolucao_saida_cfops = ['5201', '5202', '5203', '5204', '5209', '5410', '5411', '5412', '5413', '5503', '5504', '5921',
                                        '6201', '6202', '6203', '6204', '6209', '6410', '6411', '6412', '6413', '6503', '6504', '6921']

                # Industrializa√ß√£o CFOPs
                industrializacao_entrada_cfops = ['1124', '1125', '1126', '2124', '2125', '2126']
                industrializacao_saida_cfops = ['5124', '5125', '5126', '6124', '6125', '6126']

                # Categorization logic
                if cfop in manutencao_entrada_cfops or cfop in manutencao_saida_cfops:
                    return "Manuten√ß√£o/Conserto/Reparo"
                
                elif cfop in retorno_entrada_cfops or cfop in retorno_saida_cfops:
                    return "Retorno de Mercadoria"
                
                elif cfop in remessa_entrada_cfops or cfop in remessa_saida_cfops:
                    return "Remessa"
                
                elif cfop in devolucao_entrada_cfops or cfop in devolucao_saida_cfops:
                    return "Devolu√ß√£o"
                    
                elif cfop in industrializacao_entrada_cfops or cfop in industrializacao_saida_cfops:
                    return "Industrializa√ß√£o"
                
                elif cfop.startswith('3') or cfop.startswith('7'):
                    return "Importa√ß√£o/Exporta√ß√£o"
                    
                elif cfop.startswith('1') or cfop.startswith('2'):  # Entrada
                    if is_andritz_emitter:
                        return "Transfer√™ncia Entre Filiais"
                    else:
                        return "Compra de Terceiros"
                        
                elif cfop.startswith('5') or cfop.startswith('6'):  # Sa√≠da
                    if is_andritz_emitter:
                        return "Transfer√™ncia Entre Filiais"
                    else:
                        return "Venda para Terceiros"
                        
                return "Outros"  # Default category

            # Add this code after the existing DataFrame transformations but before the final column selection
            df['categoria'] = df.apply(categorize_transaction, axis=1)
            
            def categorize(row):
                """
                Categorize transactions based on CFOP and whether Andritz is the emitter
                Includes categories for maintenance, repairs, and returns
                """
                cfop = str(row['cfop'])
                emit_nome = str(row['emitNome']).upper()
                
                # Check if Andritz is the emitter
                is_andritz_emitter = 'ANDRITZ' in emit_nome
                
                # Manuten√ß√£o, Conserto e Reparo CFOPs
                manutencao_entrada_cfops = ['1915', '2915', '1916', '2916']  # Entrada para reparo
                manutencao_saida_cfops = ['5915', '6915', '5916', '6916']    # Sa√≠da para reparo
                
                # Retorno de mercadoria CFOPs
                retorno_entrada_cfops = ['1201', '1202', '1203', '1204', '1410', '1411', '1503', '1504', 
                                        '2201', '2202', '2203', '2204', '2410', '2411', '2503', '2504']
                retorno_saida_cfops = ['5201', '5202', '5210', '5410', '5411', '5412', '5413', '5503', '5504',
                                    '6201', '6202', '6210', '6410', '6411', '6412', '6413', '6503', '6504']
                
                # Remessa CFOPs
                remessa_entrada_cfops = ['1554','1901', '1902', '1903', '1904', '1905', '1906', '1907', '1908', '1909', '1913', '1914', '1921',
                                        '2901', '2902', '2903', '2904', '2905', '2906', '2907', '2908', '2909', '2913', '2914', '2921']
                remessa_saida_cfops = ['5901', '5902', '5903', '5904', '5905', '5906', '5907', '5908', '5909', '5913', '5914', '5921',
                                    '6901', '6902', '6903', '6904', '6905', '6906', '6907', '6908', '6909', '6913', '6914', '6921']
                
                # Devolu√ß√£o CFOPs
                devolucao_entrada_cfops = ['1201', '1202', '1203', '1204', '1209', '1410', '1411', '1503', '1504', '1921',
                                        '2201', '2202', '2203', '2204', '2209', '2410', '2411', '2503', '2504', '2921']
                devolucao_saida_cfops = ['5201', '5202', '5203', '5204', '5209', '5410', '5411', '5412', '5413', '5503', '5504', '5921',
                                        '6201', '6202', '6203', '6204', '6209', '6410', '6411', '6412', '6413', '6503', '6504', '6921']

                # Industrializa√ß√£o CFOPs
                industrializacao_entrada_cfops = ['1124', '1125', '1126', '2124', '2125', '2126']
                industrializacao_saida_cfops = ['5124', '5125', '5126', '6124', '6125', '6126']
                
                venda=['5101','5102','5401','5403','5405','5551','5653','5656','6101','6102','6107','6108','6401','6403','6404','5923','6653','6923']
                transf_filiais_retorno=['1949','2554','2908','2949']
                transf_filiais_envio=['6949','5554','6554','6555']
                manutencao_envio=['5915','5901','6915']
                



                # Categorization logic
                # if cfop in manutencao_entrada_cfops or cfop in manutencao_saida_cfops:
                #     return "Manuten√ß√£o/Conserto/Reparo"
                
                # elif cfop in retorno_entrada_cfops or cfop in retorno_saida_cfops:
                #     return "Retorno de Mercadoria"
                
                # elif cfop in remessa_entrada_cfops or cfop in remessa_saida_cfops:
                #     return "Remessa"
                
                # elif cfop in devolucao_entrada_cfops or cfop in devolucao_saida_cfops:
                #     return "Devolu√ß√£o"
                    
                # elif cfop in industrializacao_entrada_cfops or cfop in industrializacao_saida_cfops:
                #     return "Industrializa√ß√£o"
                
                # elif cfop.startswith('3') or cfop.startswith('7'):
                #     return "Importa√ß√£o/Exporta√ß√£o"
                    
                # elif cfop.startswith('1') or cfop.startswith('2'):  # Entrada
                #     if is_andritz_emitter:
                #         return "Transfer√™ncia Entre Filiais"
                #     else:
                #         return "Compra de Terceiros"
                        
                # elif cfop.startswith('5') or cfop.startswith('6'):  # Sa√≠da
                #     if is_andritz_emitter:
                #         return "Transfer√™ncia Entre Filiais"
                #     else:
                #         return "Venda para Terceiros"
                if cfop in manutencao_envio:  # Sa√≠da
                    if is_andritz_emitter:
                        return "Manuten√ß√£o/Conserto/Reparo - Envio"
                    else:
                        return "Manuten√ß√£o/Conserto/Reparo - Retorno"
                    
                elif cfop in venda:  # Sa√≠da
                    if is_andritz_emitter:
                        return "Transfer√™ncia Entre Filiais - venda"
                    else:
                        return "Venda de Terceiros"
                    
                elif cfop in transf_filiais_retorno:  # Sa√≠da
                    if is_andritz_emitter:
                        return "Transfer√™ncia Entre Filiais - Retorno"
                    else:
                        return "Manuten√ß√£o/Conserto/Reparo - Retorno" 
                    
                elif cfop in transf_filiais_envio:  # Sa√≠da
                    if is_andritz_emitter:
                        return "Transfer√™ncia Entre Filiais - Envio"
                    else:
                        return "Manuten√ß√£o/Conserto/Reparo - Envio"  
                                
                return "Outros"  # Default category

            # Add this code after the existing DataFrame transformations but before the final column selection
            df['my_categoria'] = df.apply(categorize, axis=1)

                       
                            # Exibir apenas as colunas renomeadas
            colunas_renomeadas = ['nNf', 'dtEmi', 'itemNf','nomeMaterial','ncm','qtd','und','vlUnProd','vlTotProd','vlTotalNf','po','dVenc','chNfe',
                                    'emitNome','emitCnpj','emitLogr','emitNr','emitCompl','emitBairro','emitMunic','emitUf','emitCep','emitPais',
                                    'destNome','destCnpj','destLogr','destNr','destCompl','destBairro','destMunic','destUf','destCep','destPais',
                                    'cfop','total_invoices_per_po', 'categoria','my_categoria','unique']
            
            df= df[colunas_renomeadas]

            groupby_cols_nf = ['chNfe']
            df['total_itens_nf'] = df.groupby(groupby_cols_nf )['qtd'].transform('sum')
            
            groupby_cols_po = ['po']
            df['total_itens_po'] = df.groupby(groupby_cols_po )['qtd'].transform('sum')
            df['valor_recebido_po'] = df.groupby(groupby_cols_po )['vlTotProd'].transform('sum')
                        
            df = df.sort_values(by=['dtEmi','nNf','itemNf'], ascending=[False,True,True])

            # Download buttons
            def convert_df_to_excel(df):
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    df.to_excel(writer, index=False, sheet_name='Invoices')
                return output.getvalue()

            def convert_df_to_pickle(df):
                return pickle.dumps(df)

            col1, col2 = st.columns(2)
            
            with col1:
                excel_file = convert_df_to_excel(df)
                st.download_button(
                    label="Download Excel",
                    data=excel_file,
                    file_name="processed_invoices.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

            with col2:
                pickle_file = convert_df_to_pickle(df)
                st.download_button(
                    label="Download Pickle",
                    data=pickle_file,
                    file_name="processed_invoices.pkl",
                    mime="application/octet-stream"
                )

            st.success(f"Processed {len(uploaded_files)} XML files")
    with tab2:
        st.header("Visualiza√ß√£o de Dados")
        if 'df' in locals():
            # Key Metrics
            col1, col2, col3 = st.columns(3)
            
            with col1:
                total_invoices = len(df)
                st.metric(label="Total de Linhas", value=total_invoices)
            
            with col2:
                unique_issuers = df['emitNome'].nunique()
                st.metric(label="N√∫mero de Fornecedores", value=unique_issuers)
            
            with col3:
                unique_issuers = df['nNf'].nunique()
                st.metric(label="N√∫mero de Notas Fiscais", value=unique_issuers)
            
            # Global Search Filter
            st.subheader("Filtrar Dados")
            search_term = st.text_input("Busca Global (filtra em todas as colunas)")
            
            if search_term:
                # Create a boolean mask that checks if the search term is in any column
                mask = df.apply(lambda row: row.astype(str).str.contains(search_term, case=False).any(), axis=1)
                filtered_df = df[mask]
            else:
                filtered_df = df
            
            # Display filtered DataFrame without index
            st.dataframe(filtered_df, hide_index=True)
            
        else:
            st.warning("Primeiro processe alguns arquivos XML na aba de Processamento")

    with tab3:
        st.header("Como Utilizar o Aplicativo")
        st.markdown("""
        ### Processamento de Arquivos XML üî¨

        1. **Carregue seus arquivos XML**
        - Clique em "Upload XML Files"
        - Selecione um ou mais arquivos XML de notas fiscais

        2. **Processamento Autom√°tico**
        - O aplicativo processar√° automaticamente os arquivos
        - Uma barra de progresso ser√° exibida durante o processamento

        3. **Visualiza√ß√£o dos Dados**
        - Os dados processados ser√£o exibidos em uma tabela
        - Voc√™ pode fazer download em formato Excel ou Pickle

        ### Recursos Principais üìä

        - Extra√ß√£o de informa√ß√µes de notas fiscais
        - Limpeza e formata√ß√£o dos dados
        - Suporte para m√∫ltiplos arquivos XML
        - Visualiza√ß√£o de dados processados
        - Download em diferentes formatos

        ### Dicas üí°

        - Certifique-se de que os arquivos XML s√£o de notas fiscais brasileiras (NF-e)
        - O processamento pode levar alguns segundos dependendo do n√∫mero de arquivos
        - Verifique sempre os dados processados antes do download

        ### Formatos Suportados
        - Arquivos XML com estrutura de Nota Fiscal Eletr√¥nica (NF-e)
        """)

if __name__ == "__main__":
    main()
    
# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>Desenvolvido com ‚ù§Ô∏è | XML Processor Pro v1.0</p>
    </div>
    """,
    unsafe_allow_html=True
)      